{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Array\n",
    "import numpy as np\n",
    "\n",
    "# Dataframe\n",
    "import pandas as pd\n",
    "\n",
    "#Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>हमें इससे बेहतर ब्राइटनेस वाले टेबलेट देखने को...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>बैटरी लाइफ बहुत बढिया है।</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>हकीकत ये है कि मेटल के नाम पर फोन में सिर्फ चा...</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>स्लोफो एक मनोरंजक एप्लिकेशन है इसमें कोई दो रा...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>अच्छी बैटरी क्षमता है।</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label\n",
       "0  हमें इससे बेहतर ब्राइटनेस वाले टेबलेट देखने को...   neg\n",
       "1                          बैटरी लाइफ बहुत बढिया है।   pos\n",
       "2  हकीकत ये है कि मेटल के नाम पर फोन में सिर्फ चा...   neu\n",
       "3  स्लोफो एक मनोरंजक एप्लिकेशन है इसमें कोई दो रा...   pos\n",
       "4                             अच्छी बैटरी क्षमता है।   pos"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data Reading\n",
    "data= pd.read_csv(r'C:\\Users\\DELL\\Desktop\\FinalYear\\StressDetection\\sentiment_analysis_term_train.csv')\n",
    "\n",
    "# Copy\n",
    "stress=data.copy()\n",
    "\n",
    "# Data\n",
    "stress.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2497</td>\n",
       "      <td>2497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2497</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>हमें इससे बेहतर ब्राइटनेस वाले टेबलेट देखने को...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>1147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text label\n",
       "count                                                2497  2497\n",
       "unique                                               2497     3\n",
       "top     हमें इससे बेहतर ब्राइटनेस वाले टेबलेट देखने को...   pos\n",
       "freq                                                    1  1147"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Statistical Information\n",
    "stress.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>हमें इससे बेहतर ब्राइटनेस वाले टेबलेट देखने को...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>बैटरी लाइफ बहुत बढिया है।</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>स्लोफो एक मनोरंजक एप्लिकेशन है इसमें कोई दो रा...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>अच्छी बैटरी क्षमता है।</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>बैटरी लाइफ की बात करें तो हमारे लगातार वीडियो ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  हमें इससे बेहतर ब्राइटनेस वाले टेबलेट देखने को...      0\n",
       "1                          बैटरी लाइफ बहुत बढिया है।      1\n",
       "3  स्लोफो एक मनोरंजक एप्लिकेशन है इसमें कोई दो रा...      1\n",
       "4                             अच्छी बैटरी क्षमता है।      1\n",
       "5  बैटरी लाइफ की बात करें तो हमारे लगातार वीडियो ...      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete rows with 'neu' label\n",
    "data = data[data['label'] != 'neu']\n",
    "\n",
    "# Convert 'pos' to 1 and 'neg' to 0\n",
    "data['label'] = data['label'].map({'pos': 1, 'neg': 0})\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation error: The read operation timed out\n"
     ]
    }
   ],
   "source": [
    "from googletrans import Translator\n",
    "\n",
    "# Initialize translator\n",
    "translator = Translator()\n",
    "\n",
    "# Function to translate text\n",
    "def translate_text(text, source_lang):\n",
    "    try:\n",
    "        translation = translator.translate(text, src=source_lang, dest='en')\n",
    "        return translation.text\n",
    "    except Exception as e:\n",
    "        print(f\"Translation error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Apply translation using Google Translate\n",
    "data['text'] = data.apply(lambda row: translate_text(row['text'], source_lang=\"hi\"), axis=1)\n",
    "\n",
    "# Remove rows with translation errors\n",
    "data = data.dropna(subset=['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>post_id</th>\n",
       "      <th>sentence_range</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>confidence</th>\n",
       "      <th>social_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ptsd</td>\n",
       "      <td>8601tu</td>\n",
       "      <td>(15, 20)</td>\n",
       "      <td>He said he had not felt that way before, sugge...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1521614353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>assistance</td>\n",
       "      <td>8lbrx9</td>\n",
       "      <td>(0, 5)</td>\n",
       "      <td>Hey there r/assistance, Not sure if this is th...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1527009817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ptsd</td>\n",
       "      <td>9ch1zh</td>\n",
       "      <td>(15, 20)</td>\n",
       "      <td>My mom then hit me with the newspaper and it s...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1535935605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>relationships</td>\n",
       "      <td>7rorpp</td>\n",
       "      <td>[5, 10]</td>\n",
       "      <td>until i met my new boyfriend, he is amazing, h...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1516429555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>survivorsofabuse</td>\n",
       "      <td>9p2gbc</td>\n",
       "      <td>[0, 5]</td>\n",
       "      <td>October is Domestic Violence Awareness Month a...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1539809005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          subreddit post_id sentence_range  \\\n",
       "0              ptsd  8601tu       (15, 20)   \n",
       "1        assistance  8lbrx9         (0, 5)   \n",
       "2              ptsd  9ch1zh       (15, 20)   \n",
       "3     relationships  7rorpp        [5, 10]   \n",
       "4  survivorsofabuse  9p2gbc         [0, 5]   \n",
       "\n",
       "                                                text  label  confidence  \\\n",
       "0  He said he had not felt that way before, sugge...      1         0.8   \n",
       "1  Hey there r/assistance, Not sure if this is th...      0         1.0   \n",
       "2  My mom then hit me with the newspaper and it s...      1         0.8   \n",
       "3  until i met my new boyfriend, he is amazing, h...      1         0.6   \n",
       "4  October is Domestic Violence Awareness Month a...      1         0.8   \n",
       "\n",
       "   social_timestamp  \n",
       "0        1521614353  \n",
       "1        1527009817  \n",
       "2        1535935605  \n",
       "3        1516429555  \n",
       "4        1539809005  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Array\n",
    "import numpy as np\n",
    "\n",
    "# Dataframe\n",
    "import pandas as pd\n",
    "\n",
    "#Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Data Reading\n",
    "stress_c= pd.read_csv(r'C:\\Users\\DELL\\Desktop\\FinalYear\\StressDetection\\Stress.csv')\n",
    "\n",
    "# Copy\n",
    "stress=stress_c.copy()\n",
    "\n",
    "# Data\n",
    "stress.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>He said he had not felt that way before, sugge...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hey there r/assistance, Not sure if this is th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>My mom then hit me with the newspaper and it s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>until i met my new boyfriend, he is amazing, h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>October is Domestic Violence Awareness Month a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  He said he had not felt that way before, sugge...      1\n",
       "1  Hey there r/assistance, Not sure if this is th...      0\n",
       "2  My mom then hit me with the newspaper and it s...      1\n",
       "3  until i met my new boyfriend, he is amazing, h...      1\n",
       "4  October is Domestic Violence Awareness Month a...      1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select only 'text' and 'label' columns\n",
    "stress = stress[['text', 'label']]\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "stress.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   text  label\n",
      "0     We have got to see tablets with better brightn...      0\n",
      "1                            Battery life is very good.      1\n",
      "2     Slopho is an entertaining application, there i...      1\n",
      "3                                Good battery capacity.      1\n",
      "4     Talking about the battery life, our consistent...      1\n",
      "...                                                 ...    ...\n",
      "4330  * Her, a week ago: Precious, how are you? (I i...      0\n",
      "4331  I don't have the ability to cope with it anymo...      1\n",
      "4332  In case this is the first time you're reading ...      0\n",
      "4333  Do you find this normal? They have a good rela...      0\n",
      "4334  I was talking to my mom this morning and she s...      1\n",
      "\n",
      "[4335 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Concatenate the rows of 'stree' onto 'data'\n",
    "merged_data = pd.concat([data, stress], ignore_index=True)\n",
    "\n",
    "# Print the concatenated DataFrame\n",
    "print(merged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of label 0: 39.23875432525952\n",
      "Percentage of label 1: 60.76124567474048\n"
     ]
    }
   ],
   "source": [
    "# Calculate the percentage of each label\n",
    "label_counts = merged_data['label'].value_counts(normalize=True) * 100\n",
    "\n",
    "# Print the percentage of each label\n",
    "print(\"Percentage of label 0:\", label_counts[0])\n",
    "print(\"Percentage of label 1:\", label_counts[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Regular Expression\n",
    "import re \n",
    "\n",
    "# Handling string\n",
    "import string\n",
    "\n",
    "# NLP tool\n",
    "import spacy\n",
    "\n",
    "nlp=spacy.load('en_core_web_sm')\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "# Importing Natural Language Tool Kit for NLP operations\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('omw-1.4')                                \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining function for preprocessing\n",
    "def preprocess(text,remove_digits=True):\n",
    "    text = re.sub('\\W+',' ', text)                                       \n",
    "    text = re.sub('\\s+',' ', text)                                       \n",
    "    text = re.sub(\"(?<!\\w)\\d+\", \"\", text)                                \n",
    "    text = re.sub(\"-(?!\\w)|(?<!\\w)-\", \"\", text)                          \n",
    "    text=text.lower()\n",
    "    nopunc=[char for char in text if char not in string.punctuation]    \n",
    "    nopunc=''.join(nopunc)\n",
    "    nopunc=' '.join([word for word in nopunc.split()\n",
    "               if word.lower() not in stopwords.words('english')])  \n",
    "    \n",
    "    \n",
    "    return nopunc\n",
    "# Defining a function for lemitization\n",
    "def lemmatize(words):\n",
    "   \n",
    "    words=nlp(words)\n",
    "    lemmas = []\n",
    "    for word in words:\n",
    "        \n",
    "        lemmas.append(word.lemma_)\n",
    "    return lemmas\n",
    "\n",
    "\n",
    "\n",
    "#converting them into string\n",
    "def listtostring(s):\n",
    "    str1=' '\n",
    "    return (str1.join(s))\n",
    "\n",
    "def clean_text(input):\n",
    "    word=preprocess(input)\n",
    "    lemmas=lemmatize(word)\n",
    "    return listtostring(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We have got to see tablets with better brightn...</td>\n",
       "      <td>0</td>\n",
       "      <td>get see tablet well brightness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Battery life is very good.</td>\n",
       "      <td>1</td>\n",
       "      <td>battery life good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Slopho is an entertaining application, there i...</td>\n",
       "      <td>1</td>\n",
       "      <td>slopho entertain application two opinion still...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Good battery capacity.</td>\n",
       "      <td>1</td>\n",
       "      <td>good battery capacity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Talking about the battery life, our consistent...</td>\n",
       "      <td>1</td>\n",
       "      <td>talk battery life consistent video playback te...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  We have got to see tablets with better brightn...      0   \n",
       "1                         Battery life is very good.      1   \n",
       "2  Slopho is an entertaining application, there i...      1   \n",
       "3                             Good battery capacity.      1   \n",
       "4  Talking about the battery life, our consistent...      1   \n",
       "\n",
       "                                          clean_text  \n",
       "0                     get see tablet well brightness  \n",
       "1                                  battery life good  \n",
       "2  slopho entertain application two opinion still...  \n",
       "3                              good battery capacity  \n",
       "4  talk battery life consistent video playback te...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a feature to store clean texts\n",
    "merged_data['clean_text']=merged_data['text'].apply(clean_text)\n",
    "merged_data.to_csv('merged_data_with_clean_text.csv', index=False)\n",
    "\n",
    "merged_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorization\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "\n",
    "\n",
    "# Model Building\n",
    "from sklearn.model_selection import GridSearchCV,StratifiedKFold,KFold,train_test_split,cross_val_score,cross_val_predict\n",
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import StackingClassifier,RandomForestClassifier,AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#Model Evaluation\n",
    "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score,f1_score,precision_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Time\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining target & feature for ML model building\n",
    "x=merged_data['clean_text']\n",
    "y=merged_data['label']\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0.032631874084472656\n",
      "Accuracy: 0.7381776239907728\n",
      "==============================================================================================================\n",
      "Confusion Matrix:\n",
      " [[171 156]\n",
      " [ 71 469]]\n",
      "==============================================================================================================\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.52      0.60       327\n",
      "           1       0.75      0.87      0.81       540\n",
      "\n",
      "    accuracy                           0.74       867\n",
      "   macro avg       0.73      0.70      0.70       867\n",
      "weighted avg       0.73      0.74      0.73       867\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from time import time\n",
    "\n",
    "def train_and_evaluate_model(model, x_train, x_test, y_train, y_test, vectorizer='tfidf'):\n",
    "    if vectorizer == 'tfidf':\n",
    "        vector = TfidfVectorizer()\n",
    "    elif vectorizer == 'bow':\n",
    "        vector = CountVectorizer()\n",
    "    elif vectorizer == 'onehot':\n",
    "        vector = OneHotEncoder()\n",
    "        x_train = vector.fit_transform(x_train).toarray()\n",
    "        x_test = vector.transform(x_test).toarray()\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"Vectorizer should be one of 'tfidf', 'bow', or 'onehot'.\")\n",
    "\n",
    "    if vectorizer != 'onehot':\n",
    "        x_train = vector.fit_transform(x_train)\n",
    "        x_test = vector.transform(x_test)\n",
    " \n",
    "    # Fitting training data into the model & predicting\n",
    "    t0 = time()\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    \n",
    "    # Model Evaluation\n",
    "    conf = confusion_matrix(y_test, y_pred)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    print('Time taken:', time() - t0)\n",
    "    print('Accuracy:', acc)\n",
    "    print(10 * '===========')\n",
    "    print('Confusion Matrix:\\n', conf)\n",
    "    print(10 * '===========')\n",
    "    print('Classification Report:\\n', classification_report(y_test, y_pred))\n",
    "    \n",
    "    return y_test, y_pred, acc\n",
    "\n",
    "# Example usage:\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=1)\n",
    "\n",
    "# Define your model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Train and evaluate the model using TF-IDF\n",
    "true_labels, predicted_labels, accuracy = train_and_evaluate_model(model, x_train, x_test, y_train, y_test, vectorizer='tfidf')\n",
    "\n",
    "\n",
    "# Train and evaluate the model using bag-of-words\n",
    "#true_labels, predicted_labels, accuracy = train_and_evaluate_model(model, x_train, x_test, y_train, y_test, vectorizer='bow')\n",
    "\n",
    "# Train and evaluate the model using one-hot encoding\n",
    "#true_labels, predicted_labels, accuracy = train_and_evaluate_model(model, x_train, x_test, y_train, y_test, vectorizer='onehot')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'acc_lr_tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m tbl\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[0;32m      2\u001b[0m tbl[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mSeries([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLogistic Regresion\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMultinomial NB\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      3\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDecision Tree\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRandom Forest\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAdaptive Boosting\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOne-Hot-LR\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBOW-LR\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMB-BOW\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMB-OH\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDT-BOW\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDT-OH\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRF-BOW\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRF-OH\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAB-BOW\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAB-OH\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLR-NG\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m----> 4\u001b[0m tbl[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mSeries([\u001b[43macc_lr_tf\u001b[49m,acc_nb_tf,acc_dt_tf,\n\u001b[0;32m      5\u001b[0m                   acc_rf_tf,acc_ab_tf,acc_lr_one_hot,acc_lr_bow,acc_nb_bow,acc_nb_one_hot,acc_dt_bow,acc_dt_one_hot,acc_rf_bow,acc_rf_one_hot,acc_ab_bow,acc_ab_one_hot,acc_lr_ng])\n\u001b[0;32m      6\u001b[0m tbl[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF1_Score\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mSeries([f1_lr_tf,f1_nb_tf,f1_dt_tf,\n\u001b[0;32m      7\u001b[0m                   f1_rf_tf,f1_ab_tf,f1_lr_one_hot,f1_lr_bow,f1_nb_bow,f1_nb_one_hot,f1_dt_bow,f1_dt_one_hot,f1_rf_bow,f1_rf_one_hot,f1_ab_bow,f1_ab_one_hot,f1_lr_ng])\n\u001b[0;32m      8\u001b[0m tbl\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'acc_lr_tf' is not defined"
     ]
    }
   ],
   "source": [
    "tbl=pd.DataFrame()\n",
    "tbl['Model']=pd.Series(['Logistic Regresion','Multinomial NB',\n",
    "            'Decision Tree','Random Forest','Adaptive Boosting','One-Hot-LR','BOW-LR','MB-BOW','MB-OH','DT-BOW','DT-OH','RF-BOW','RF-OH','AB-BOW','AB-OH','LR-NG'])\n",
    "tbl['Accuracy']=pd.Series([acc_lr_tf,acc_nb_tf,acc_dt_tf,\n",
    "                  acc_rf_tf,acc_ab_tf,acc_lr_one_hot,acc_lr_bow,acc_nb_bow,acc_nb_one_hot,acc_dt_bow,acc_dt_one_hot,acc_rf_bow,acc_rf_one_hot,acc_ab_bow,acc_ab_one_hot,acc_lr_ng])\n",
    "tbl['F1_Score']=pd.Series([f1_lr_tf,f1_nb_tf,f1_dt_tf,\n",
    "                  f1_rf_tf,f1_ab_tf,f1_lr_one_hot,f1_lr_bow,f1_nb_bow,f1_nb_one_hot,f1_dt_bow,f1_dt_one_hot,f1_rf_bow,f1_rf_one_hot,f1_ab_bow,f1_ab_one_hot,f1_lr_ng])\n",
    "tbl.set_index('Model')\n",
    "# Best model on the basis of F1 Score\n",
    "tbl.sort_values('F1_Score',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Model  Accuracy  F1 Score\n",
      "0      Logistic Regression  0.734155  0.734750\n",
      "1                      SVM  0.744718  0.745219\n",
      "2            Decision Tree  0.610915  0.612114\n",
      "3            Random Forest  0.709507  0.707983\n",
      "4                 AdaBoost  0.658451  0.659575\n",
      "5  Multinomial Naive Bayes  0.727113  0.713342\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from time import time\n",
    "import pandas as pd\n",
    "\n",
    "def train_and_evaluate_model(model, x_train, x_test, y_train, y_test, vectorizer='tfidf'):\n",
    "    if vectorizer == 'tfidf':\n",
    "        vector = TfidfVectorizer()\n",
    "    elif vectorizer == 'bow':\n",
    "        vector = CountVectorizer()\n",
    "    elif vectorizer == 'onehot':\n",
    "        vector = OneHotEncoder()\n",
    "        x_train = vector.fit_transform(x_train).toarray()\n",
    "        x_test = vector.transform(x_test).toarray()\n",
    "    else:\n",
    "        raise ValueError(\"Vectorizer should be one of 'tfidf', 'bow', or 'onehot'.\")\n",
    "\n",
    "    if vectorizer != 'onehot':\n",
    "        x_train = vector.fit_transform(x_train)\n",
    "        x_test = vector.transform(x_test)\n",
    " \n",
    "    # Fitting training data into the model & predicting\n",
    "    t0 = time()\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    \n",
    "    # Model Evaluation\n",
    "    conf = confusion_matrix(y_test, y_pred)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    return acc, f1\n",
    "\n",
    "# Example usage:\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1)\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"SVM\": SVC(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"AdaBoost\": AdaBoostClassifier(),\n",
    "    \"Multinomial Naive Bayes\": MultinomialNB()\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    acc, f1 = train_and_evaluate_model(model, x_train, x_test, y_train, y_test, vectorizer='tfidf')\n",
    "    results.append([name, acc, f1])\n",
    "\n",
    "results_df = pd.DataFrame(results, columns=[\"Model\", \"Accuracy\", \"F1 Score\"])\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Model  Accuracy  F1 Score\n",
      "0      Logistic Regression  0.700704  0.701765\n",
      "1                      SVM  0.709507  0.710544\n",
      "2            Decision Tree  0.600352  0.600265\n",
      "3            Random Forest  0.720070  0.717556\n",
      "4                 AdaBoost  0.632042  0.633308\n",
      "5  Multinomial Naive Bayes  0.739437  0.734744\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from time import time\n",
    "import pandas as pd\n",
    "\n",
    "def train_and_evaluate_model(model, x_train, x_test, y_train, y_test, vectorizer='tfidf'):\n",
    "    if vectorizer == 'tfidf':\n",
    "        vector = TfidfVectorizer()\n",
    "    elif vectorizer == 'bow':\n",
    "        vector = CountVectorizer()\n",
    "    elif vectorizer == 'onehot':\n",
    "        vector = OneHotEncoder()\n",
    "        x_train = vector.fit_transform(x_train).toarray()\n",
    "        x_test = vector.transform(x_test).toarray()\n",
    "    else:\n",
    "        raise ValueError(\"Vectorizer should be one of 'tfidf', 'bow', or 'onehot'.\")\n",
    "\n",
    "    if vectorizer != 'onehot':\n",
    "        x_train = vector.fit_transform(x_train)\n",
    "        x_test = vector.transform(x_test)\n",
    " \n",
    "    # Fitting training data into the model & predicting\n",
    "    t0 = time()\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    \n",
    "    # Model Evaluation\n",
    "    conf = confusion_matrix(y_test, y_pred)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    return acc, f1\n",
    "\n",
    "# Example usage:\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1)\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"SVM\": SVC(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"AdaBoost\": AdaBoostClassifier(),\n",
    "    \"Multinomial Naive Bayes\": MultinomialNB()\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    acc, f1 = train_and_evaluate_model(model, x_train, x_test, y_train, y_test, vectorizer='bow')\n",
    "    results.append([name, acc, f1])\n",
    "\n",
    "results_df = pd.DataFrame(results, columns=[\"Model\", \"Accuracy\", \"F1 Score\"])\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Model  Accuracy  F1 Score\n",
      "0      Logistic Regression  0.566901  0.417571\n",
      "1                      SVM  0.566901  0.417571\n",
      "2            Decision Tree  0.566901  0.420546\n",
      "3            Random Forest  0.566901  0.417571\n",
      "4                 AdaBoost  0.561620  0.405847\n",
      "5  Multinomial Naive Bayes  0.566901  0.417571\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from time import time\n",
    "import pandas as pd\n",
    "\n",
    "def train_and_evaluate_model(model, x_train, x_test, y_train, y_test, vectorizer='tfidf'):\n",
    "    if vectorizer == 'tfidf':\n",
    "        vector = TfidfVectorizer()\n",
    "    elif vectorizer == 'bow':\n",
    "        vector = CountVectorizer()\n",
    "    elif vectorizer == 'onehot':\n",
    "        vector = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "        x_train_reshaped = x_train.values.reshape(-1, 1)\n",
    "        x_test_reshaped = x_test.values.reshape(-1, 1)\n",
    "    \n",
    "        x_train = vector.fit_transform(x_train_reshaped)\n",
    "        x_test = vector.transform(x_test_reshaped)\n",
    "    else:\n",
    "        raise ValueError(\"Vectorizer should be one of 'tfidf', 'bow', or 'onehot'.\")\n",
    "\n",
    "    if vectorizer != 'onehot':\n",
    "        x_train = vector.fit_transform(x_train)\n",
    "        x_test = vector.transform(x_test)\n",
    " \n",
    "    # Fitting training data into the model & predicting\n",
    "    t0 = time()\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    \n",
    "    # Model Evaluation\n",
    "    conf = confusion_matrix(y_test, y_pred)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    return acc, f1\n",
    "\n",
    "# Example usage:\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1)\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"SVM\": SVC(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"AdaBoost\": AdaBoostClassifier(random_state=1),\n",
    "    \"Multinomial Naive Bayes\": MultinomialNB()\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    acc, f1 = train_and_evaluate_model(model, x_train, x_test, y_train, y_test, vectorizer='onehot')\n",
    "    results.append([name, acc, f1])\n",
    "\n",
    "results_df = pd.DataFrame(results, columns=[\"Model\", \"Accuracy\", \"F1 Score\"])\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "# Assuming you have already loaded your training data X_train\n",
    "# Obtain BERT embeddings for training data\n",
    "\n",
    "def get_bert_embeddings(texts):\n",
    "    # Load pre-trained BERT model and tokenizer\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    # Define a function to obtain BERT embeddings for a single text\n",
    "    def get_single_bert_embedding(text):\n",
    "        input_ids = tokenizer(text, return_tensors='pt', padding=True, truncation=True)['input_ids']\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids)\n",
    "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
    "        return embeddings\n",
    "\n",
    "    # Obtain BERT embeddings for all texts\n",
    "    embeddings_list = [get_single_bert_embedding(text) for text in texts]\n",
    "    return embeddings_list\n",
    "\n",
    "df = pd.read_csv(r'C:\\Users\\DELL\\Desktop\\FinalYear\\StressDetection\\merged_data_with_clean_text.csv')\n",
    "\n",
    "X_train = df['clean_text']\n",
    "y_train = df['label']\n",
    "x_train_embeddings = [get_bert_embeddings(text) for text in X_train]\n",
    "\n",
    "def predict_stressfulness(text):\n",
    "    # Obtain BERT embedding for the input text\n",
    "    embedding = get_bert_embeddings(text)\n",
    "\n",
    "    # Load the trained logistic regression classifier\n",
    "    lr_classifier = LogisticRegression(max_iter=1000)\n",
    "    lr_classifier.fit(x_train_embeddings, y_train)\n",
    "\n",
    "    # Predict the stressfulness of the input text\n",
    "    predicted_label = lr_classifier.predict([embedding])[0]\n",
    "    if predicted_label == 1:\n",
    "        return \"The text is stressful.\"\n",
    "    else:\n",
    "        return \"The text is not stressful.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7254901960784313\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(r'C:\\Users\\DELL\\Desktop\\FinalYear\\StressDetection\\merged_data_with_clean_text.csv')\n",
    "\n",
    "# Split the data into features (X) and target labels (y)\n",
    "X = df['clean_text']\n",
    "y = df['label']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Obtain BERT embeddings for training and testing data\n",
    "x_train_embeddings = get_bert_embeddings(x_train)\n",
    "x_test_embeddings = get_bert_embeddings(x_test)\n",
    "\n",
    "# Define and train the classifier\n",
    "classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "classifier.fit(x_train_embeddings, y_train)\n",
    "\n",
    "    # Predict on test set\n",
    "y_pred = classifier.predict(x_test_embeddings)\n",
    "\n",
    "    # Evaluate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.7254901960784313\n",
      "Logistic Regression Accuracy: 0.7185697808535179\n",
      "Support Vector Machine Accuracy: 0.7450980392156863\n",
      "Decision Tree Accuracy: 0.615916955017301\n",
      "AdaBoost Accuracy: 0.6966551326412919\n",
      "Multinomial Naive Bayes Accuracy: 0.5870818915801614\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "def get_bert_embeddings(texts):\n",
    "    # Load pre-trained BERT model and tokenizer\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    # Define a function to obtain BERT embeddings for a single text\n",
    "    def get_single_bert_embedding(text):\n",
    "        input_ids = tokenizer(text, return_tensors='pt', padding=True, truncation=True)['input_ids']\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids)\n",
    "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
    "        return embeddings\n",
    "\n",
    "    # Obtain BERT embeddings for all texts\n",
    "    embeddings_list = [get_single_bert_embedding(text) for text in texts]\n",
    "    return embeddings_list\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(r'C:\\Users\\DELL\\Desktop\\FinalYear\\StressDetection\\merged_data_with_clean_text.csv')\n",
    "\n",
    "# Split the data into features (X) and target labels (y)\n",
    "X = df['clean_text']\n",
    "y = df['label']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Obtain BERT embeddings for training and testing data\n",
    "x_train_embeddings = get_bert_embeddings(x_train)\n",
    "x_test_embeddings = get_bert_embeddings(x_test)\n",
    "\n",
    "# Define and train classifiers\n",
    "\n",
    "# Logistic Regression\n",
    "lr_classifier = LogisticRegression(max_iter=1000)\n",
    "lr_classifier.fit(x_train_embeddings, y_train)\n",
    "lr_pred = lr_classifier.predict(x_test_embeddings)\n",
    "lr_accuracy = accuracy_score(y_test, lr_pred)\n",
    "print(\"Logistic Regression Accuracy:\", lr_accuracy)\n",
    "\n",
    "# Random Forest\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(x_train_embeddings, y_train)\n",
    "rf_pred = rf_classifier.predict(x_test_embeddings)\n",
    "rf_accuracy = accuracy_score(y_test, rf_pred)\n",
    "print(\"Random Forest Accuracy:\", rf_accuracy)\n",
    "\n",
    "# # Logistic Regression\n",
    "# lr_classifier = LogisticRegression(max_iter=1000)\n",
    "# lr_classifier.fit(x_train_embeddings, y_train)\n",
    "# lr_pred = lr_classifier.predict(x_test_embeddings)\n",
    "# lr_accuracy = accuracy_score(y_test, lr_pred)\n",
    "# print(\"Logistic Regression Accuracy:\", lr_accuracy)\n",
    "\n",
    "# Support Vector Machine\n",
    "svm_classifier = SVC()\n",
    "svm_classifier.fit(x_train_embeddings, y_train)\n",
    "svm_pred = svm_classifier.predict(x_test_embeddings)\n",
    "svm_accuracy = accuracy_score(y_test, svm_pred)\n",
    "print(\"Support Vector Machine Accuracy:\", svm_accuracy)\n",
    "\n",
    "# Decision Tree\n",
    "dt_classifier = DecisionTreeClassifier()\n",
    "dt_classifier.fit(x_train_embeddings, y_train)\n",
    "dt_pred = dt_classifier.predict(x_test_embeddings)\n",
    "dt_accuracy = accuracy_score(y_test, dt_pred)\n",
    "print(\"Decision Tree Accuracy:\", dt_accuracy)\n",
    "\n",
    "# AdaBoost\n",
    "adb_classifier = AdaBoostClassifier(n_estimators=100)\n",
    "adb_classifier.fit(x_train_embeddings, y_train)\n",
    "adb_pred = adb_classifier.predict(x_test_embeddings)\n",
    "adb_accuracy = accuracy_score(y_test, adb_pred)\n",
    "print(\"AdaBoost Accuracy:\", adb_accuracy)\n",
    "\n",
    "# Multinomial Naive Bayes\n",
    "mnb_classifier = MultinomialNB()\n",
    "# Multinomial Naive Bayes requires non-negative inputs, so we can't directly use BERT embeddings\n",
    "# We need to convert them to non-negative values first\n",
    "x_train_non_negative = [[max(0, val) for val in emb] for emb in x_train_embeddings]\n",
    "x_test_non_negative = [[max(0, val) for val in emb] for emb in x_test_embeddings]\n",
    "mnb_classifier.fit(x_train_non_negative, y_train)\n",
    "mnb_pred = mnb_classifier.predict(x_test_non_negative)\n",
    "mnb_accuracy = accuracy_score(y_test, mnb_pred)\n",
    "print(\"Multinomial Naive Bayes Accuracy:\", mnb_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "text_input = input(\"Enter the text: \")\n",
    "result = predict_stressfulness(text_input)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify, render_template\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from googletrans import Translator\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "def get_bert_embeddings(texts):\n",
    "    # Load pre-trained BERT model and tokenizer\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    # Define a function to obtain BERT embeddings for a single text\n",
    "    def get_single_bert_embedding(text):\n",
    "        input_ids = tokenizer(text, return_tensors='pt', padding=True, truncation=True)['input_ids']\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids)\n",
    "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
    "        return embeddings\n",
    "\n",
    "    # Obtain BERT embeddings for all texts\n",
    "    embeddings_list = [get_single_bert_embedding(text) for text in texts]\n",
    "    return embeddings_list\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(r'C:\\Users\\DELL\\Desktop\\FinalYear\\StressDetection\\merged_data_with_clean_text.csv')\n",
    "\n",
    "# Split the data into features (X) and target labels (y)\n",
    "X = df['clean_text']\n",
    "y = df['label']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Obtain BERT embeddings for training and testing data\n",
    "x_train_embeddings = get_bert_embeddings(x_train)\n",
    "x_test_embeddings = get_bert_embeddings(x_test)\n",
    "\n",
    "# Define and train classifiers\n",
    "# Logistic Regression\n",
    "lr_classifier = LogisticRegression(max_iter=1000)\n",
    "lr_classifier.fit(x_train_embeddings, y_train)\n",
    "\n",
    "# Random Forest\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(x_train_embeddings, y_train)\n",
    "\n",
    "# Support Vector Machine\n",
    "svm_classifier = SVC()\n",
    "svm_classifier.fit(x_train_embeddings, y_train)\n",
    "\n",
    "# Decision Tree\n",
    "dt_classifier = DecisionTreeClassifier()\n",
    "dt_classifier.fit(x_train_embeddings, y_train)\n",
    "\n",
    "# AdaBoost\n",
    "adb_classifier = AdaBoostClassifier(n_estimators=100)\n",
    "adb_classifier.fit(x_train_embeddings, y_train)\n",
    "\n",
    "# Multinomial Naive Bayes\n",
    "mnb_classifier = MultinomialNB()\n",
    "x_train_non_negative = [[max(0, val) for val in emb] for emb in x_train_embeddings]\n",
    "x_test_non_negative = [[max(0, val) for val in emb] for emb in x_test_embeddings]\n",
    "mnb_classifier.fit(x_train_non_negative, y_train)\n",
    "\n",
    "# Function to translate text from Hindi to English\n",
    "def translate_to_english(text):\n",
    "    translator = Translator()\n",
    "    translation = translator.translate(text, src='hi', dest='en')\n",
    "    return translation.text\n",
    "\n",
    "# Function to predict stressfulness\n",
    "def predict_stressfulness(text, language):\n",
    "    if language == 'hindi':\n",
    "        text = translate_to_english(text)\n",
    "    embedding = get_bert_embeddings([text])[0]\n",
    "    prediction = lr_classifier.predict([embedding])[0]  # You can change the classifier here as needed\n",
    "    return prediction\n",
    "\n",
    "# Route for home page\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return render_template('index.html')\n",
    "\n",
    "# Route for prediction\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    text = request.form['text']\n",
    "    language = request.form['language']  # Assuming language selection is done through a dropdown\n",
    "    prediction = predict_stressfulness(text, language)\n",
    "    return render_template('result.html', prediction=prediction)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
